{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2bf461",
   "metadata": {},
   "source": [
    "I used the Reddit API, and the UCD subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266b38e",
   "metadata": {},
   "source": [
    "For this project, we are going to collect data from Reddit, speciffically to investigate the UCD subreddit. We are choosing the praw wrapper to try to better learn how to use wrappers in calling to an api. We are going to invistigate some of the social dynamics of the UCD Subreddit. Collecting the data from UCD Subreddit using praw we collect both the top submissions to the UCD Subreddit, and all comments within those submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cc94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Obtaining dependency information for praw from https://files.pythonhosted.org/packages/81/6a/21bc058bcccbe03f6a0895bf1bd60c805f0c526aa4e9bfaac775ed0b299c/praw-7.7.1-py3-none-any.whl.metadata\n",
      "  Downloading praw-7.7.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting prawcore<3,>=2.1 (from praw)\n",
      "  Obtaining dependency information for prawcore<3,>=2.1 from https://files.pythonhosted.org/packages/96/5c/8af904314e42d5401afcfaff69940dc448e974f80f7aa39b241a4fbf0cf1/prawcore-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update-checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Users/zach/anaconda3/lib/python3.11/site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/zach/anaconda3/lib/python3.11/site-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
      "Requirement already satisfied: six in /Users/zach/anaconda3/lib/python3.11/site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zach/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zach/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zach/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zach/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n",
      "Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: update-checker, prawcore, praw\n",
      "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08135c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43469840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zach/Desktop/datasciencewithpython\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891a619",
   "metadata": {},
   "source": [
    "Below are the different keys needed the api to allow for the accesses. We can cread an object reddit that has all the keys needed for the api retrieval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa043ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id= \"######\",\n",
    "                     client_secret= \"######\",\n",
    "                    user_agent = \"#####\",\n",
    "                    username = \"#####\",\n",
    "                    password = \"######\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c501241",
   "metadata": {},
   "source": [
    "Using praw to retrieve submissions and comments, we will first get the submissions for the UCD subreddit. There are a few different ways of obtaining the submissions within the Praw wrapper: controversial, gilded, hot, new, rising, top. I chose top for this project. Setting the limit= None allows us to grab up to 1000 submissions to the subreddit. The time_filter is set to the past 'year'. We will collect the information of each submission by the id, title, author, time(created_utc), and comments retrieved. It is important that we set the final row in the variable of 'comments_retrieved' to be False, so that later on when we are collecting the data, we can update this paramter to true if we to retrieve the comment. This allows for when an error message can occur, we create a \"save game\" spot so when running through the loop, the code \"knows where to go\" and only make calls for comments with the comments_retrieved set to \"false\". We also need to add add a try block in case an \"author's name is None\" because of the error that can happen if the auhtor's name is missing. This appears to be because someone deleted their reddit account or no longer has a reddit account as it may have been removed/banned, but the post is still online.\n",
    "\n",
    "The documentation that helped a lot with this is the praw documentation for the submission instance. Grabbing the \"id\" of the submissions is also quite important as it can be used later when grabbing the comments data. https://praw.readthedocs.io/en/stable/getting_started/quick_start.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3a23c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11gyf77\n",
      "10wtrb7\n",
      "zt2gxl\n",
      "zgd8dy\n",
      "116gory\n",
      "13j2389\n",
      "11bp4rq\n",
      "13qfeni\n",
      "1300qud\n",
      "114lr14\n",
      "z9zgdw\n",
      "170oye6\n",
      "141icfm\n",
      "13j6rs6\n",
      "zuq0h7\n",
      "z3qojz\n",
      "yrc7pu\n",
      "16bgy4y\n",
      "10h3j7z\n"
     ]
    }
   ],
   "source": [
    "with open('./submissions.csv', 'w') as f:\n",
    "    out = csv.writer(f)\n",
    "    out.writerow(['id', 'title', 'author', 'created_utc', 'comments_retrieved'])\n",
    "    for submission in reddit.subreddit('UCD').top(limit=None, time_filter = 'year'):\n",
    "        try:\n",
    "            name = submission.author.name\n",
    "        except AttributeError:\n",
    "            name = None\n",
    "            print(submission)\n",
    "        out.writerow([submission.id, submission.title, name, submission.created_utc, False])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82cc06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./submissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "172a4102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>comments_retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176x1xq</td>\n",
       "      <td>UCD bathrooms are wild</td>\n",
       "      <td>That_Bison_5628</td>\n",
       "      <td>1.697198e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16fc7qv</td>\n",
       "      <td>!! DOES ANYONE HAVE A FLOOR/MATTRESS I COULD S...</td>\n",
       "      <td>These-Occasion-1529</td>\n",
       "      <td>1.694381e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17hw6g0</td>\n",
       "      <td>How do I bring this up to my roomates?</td>\n",
       "      <td>filmfan4</td>\n",
       "      <td>1.698437e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17grx2v</td>\n",
       "      <td>Sick of exclusion and rude people</td>\n",
       "      <td>Curious_Bus2391</td>\n",
       "      <td>1.698310e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16mp12l</td>\n",
       "      <td>Thinking of dropping out</td>\n",
       "      <td>gotmyeyeonme</td>\n",
       "      <td>1.695125e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  176x1xq                             UCD bathrooms are wild   \n",
       "1  16fc7qv  !! DOES ANYONE HAVE A FLOOR/MATTRESS I COULD S...   \n",
       "2  17hw6g0             How do I bring this up to my roomates?   \n",
       "3  17grx2v                  Sick of exclusion and rude people   \n",
       "4  16mp12l                           Thinking of dropping out   \n",
       "\n",
       "                author   created_utc  comments_retrieved  \n",
       "0      That_Bison_5628  1.697198e+09                True  \n",
       "1  These-Occasion-1529  1.694381e+09                True  \n",
       "2             filmfan4  1.698437e+09                True  \n",
       "3      Curious_Bus2391  1.698310e+09                True  \n",
       "4         gotmyeyeonme  1.695125e+09                True  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64865502",
   "metadata": {},
   "source": [
    "Because this call can be interupted and we can get an error message for making too many calls to the api, we want to begin with an if not, so that we do not keep rewriting over the same csv file. Here we are creating a csv and appending the information we are grabbing from the comments, which is the comments id, the body of the text, the author, the time, the \"parent id\"(who the comment was made to), the submission id (which submission is this part of), the amount of awards received for a comment, the upvotes the comment recieved, the down votes of the comment, as well as the overall \"score\" of the comment(how many total up and down votes it recieved). The amount of awards received, the upvotes and down votes, and the score may give insight into the comment, not just information regarding the network position of a comment/author.\n",
    "\n",
    "Because we grabbed the submission id previously, we can use this to find all the comments within that submission. As the api returns a list via praw, again we are writing this to a csv. We use a lot of the documentation from praw and more information can be found here:\n",
    "https://praw.readthedocs.io/en/stable/tutorials/comments.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eba57a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving comments for 15uqkwv\n",
      "Retrieving comments for 15uko8s\n",
      "Retrieving comments for 15ti0t0\n",
      "Retrieving comments for 15n8dfz\n",
      "Retrieving comments for 15n50s4\n",
      "Retrieving comments for 15mp7k5\n",
      "Retrieving comments for 15i0an3\n",
      "Retrieving comments for 15gbyez\n",
      "Retrieving comments for 15g2g90\n",
      "Retrieving comments for 15ekj4v\n",
      "Retrieving comments for 15dsfu0\n",
      "Retrieving comments for 157clzd\n",
      "Retrieving comments for 156ac38\n",
      "Retrieving comments for 1560gla\n",
      "Retrieving comments for 154mcal\n",
      "Retrieving comments for 152w0q2\n",
      "Retrieving comments for 151g0rb\n",
      "Retrieving comments for 1515jql\n",
      "Retrieving comments for 150lcnq\n",
      "Retrieving comments for 14z6uop\n",
      "Retrieving comments for 14x3qxc\n",
      "Retrieving comments for 14ta0pv\n",
      "Retrieving comments for 14nqk4d\n",
      "Retrieving comments for 14nb4ml\n",
      "Retrieving comments for 14mbufi\n",
      "Retrieving comments for 14m72py\n",
      "Retrieving comments for 14l7vfj\n",
      "Retrieving comments for 14jt0fi\n",
      "Retrieving comments for 14jjjye\n",
      "Retrieving comments for 14hwwu6\n",
      "Retrieving comments for 14hrh9c\n",
      "Retrieving comments for 14fy56u\n",
      "Retrieving comments for 14epcg2\n",
      "Retrieving comments for 14az8db\n",
      "Retrieving comments for 14948cc\n",
      "Retrieving comments for 147q4m2\n",
      "Retrieving comments for 144jzg6\n",
      "Retrieving comments for 1446yex\n",
      "Retrieving comments for 1446we2\n",
      "Retrieving comments for 14393bx\n",
      "Retrieving comments for 142jl2v\n",
      "Retrieving comments for 141icfm\n",
      "Retrieving comments for 1416vbf\n",
      "Retrieving comments for 14151pl\n",
      "Retrieving comments for 13zuq39\n",
      "Retrieving comments for 13xoxwz\n",
      "Retrieving comments for 13xdo33\n",
      "Retrieving comments for 13v2h2r\n",
      "Retrieving comments for 13syd24\n",
      "Retrieving comments for 13sku1q\n",
      "Retrieving comments for 13rcp8t\n",
      "Retrieving comments for 13pplpx\n",
      "Retrieving comments for 13lokid\n",
      "Retrieving comments for 13kv9u0\n",
      "Retrieving comments for 13kv3o3\n",
      "Retrieving comments for 13j7j2s\n",
      "Retrieving comments for 13j6rs6\n",
      "Retrieving comments for 13imjbi\n",
      "Retrieving comments for 13f2xze\n",
      "Retrieving comments for 139re9u\n",
      "Retrieving comments for 139ifi6\n",
      "Retrieving comments for 138pqpo\n",
      "Retrieving comments for 138kqdq\n",
      "Retrieving comments for 136snda\n",
      "Retrieving comments for 135f1ub\n",
      "Retrieving comments for 13415d6\n",
      "Retrieving comments for 1330uhs\n",
      "Retrieving comments for 132lnh1\n",
      "Retrieving comments for 130lly4\n",
      "Retrieving comments for 13019n2\n",
      "Retrieving comments for 12xwzk4\n",
      "Retrieving comments for 12w8p54\n",
      "Retrieving comments for 12w2fpk\n",
      "Retrieving comments for 12vcu33\n",
      "Retrieving comments for 12qzdtw\n",
      "Retrieving comments for 12pcg8t\n",
      "Retrieving comments for 12orabt\n",
      "Retrieving comments for 12oh8cf\n",
      "Retrieving comments for 12jkcml\n",
      "Retrieving comments for 12dhjan\n",
      "Retrieving comments for 125fbem\n",
      "Retrieving comments for 124maox\n",
      "Retrieving comments for 1244x5k\n",
      "Retrieving comments for 123tpeh\n",
      "Retrieving comments for 11u4zj8\n",
      "Retrieving comments for 11o9e3l\n",
      "Retrieving comments for 11gv4ve\n",
      "Retrieving comments for 11evqbg\n",
      "Retrieving comments for 11eddgi\n",
      "Retrieving comments for 11dfap7\n",
      "Retrieving comments for 11dd8zx\n",
      "Retrieving comments for 11chtt9\n",
      "Retrieving comments for 11buoki\n",
      "Retrieving comments for 11blaic\n",
      "Retrieving comments for 115lc84\n",
      "Retrieving comments for 112d4n6\n",
      "Retrieving comments for 1127d4v\n",
      "Retrieving comments for 1122vvd\n",
      "Retrieving comments for 1109fi5\n",
      "Retrieving comments for 10zhbmh\n",
      "Retrieving comments for 10y77s5\n",
      "Retrieving comments for 10y2q3p\n",
      "Retrieving comments for 10xi21s\n",
      "Retrieving comments for 10xde1a\n",
      "Retrieving comments for 10x1zse\n",
      "Retrieving comments for 10twnqw\n",
      "Retrieving comments for 10sdtkf\n",
      "Retrieving comments for 10r1cff\n",
      "Retrieving comments for 10qyt1i\n",
      "Retrieving comments for 10qkibp\n",
      "Retrieving comments for 10phamx\n",
      "Retrieving comments for 10pd38s\n",
      "Retrieving comments for 10pbsf4\n",
      "Retrieving comments for 10ofuy1\n",
      "Retrieving comments for 10nzr3v\n",
      "Retrieving comments for 10ixorz\n",
      "Retrieving comments for 10ei2zz\n",
      "Retrieving comments for 10ee7cq\n",
      "Retrieving comments for 10dslet\n",
      "Retrieving comments for 108tcrn\n",
      "Retrieving comments for 1077hh4\n",
      "Retrieving comments for 106yetv\n",
      "Retrieving comments for 105q38n\n",
      "Retrieving comments for 105nkmp\n",
      "Retrieving comments for 103fk1y\n",
      "Retrieving comments for 102k69v\n",
      "Retrieving comments for zz7iic\n",
      "Retrieving comments for zxiti6\n",
      "Retrieving comments for zuq0h7\n",
      "Retrieving comments for ztpfws\n",
      "Retrieving comments for zlmvu8\n",
      "Retrieving comments for zkvqzl\n",
      "Retrieving comments for z9mp01\n",
      "Retrieving comments for z8qo9i\n",
      "Retrieving comments for z4bj2y\n",
      "Retrieving comments for z3qojz\n",
      "Retrieving comments for z3mt2z\n",
      "Retrieving comments for z2nexz\n",
      "Retrieving comments for z1pobz\n",
      "Retrieving comments for yrc7pu\n",
      "Retrieving comments for yl4lf5\n",
      "Retrieving comments for 17k009c\n",
      "Retrieving comments for 17j4x09\n",
      "Retrieving comments for 17gws73\n",
      "Retrieving comments for 17gtrbm\n",
      "Retrieving comments for 17gtnkc\n",
      "Retrieving comments for 17gs31t\n",
      "Retrieving comments for 17fkivk\n",
      "Retrieving comments for 17fc260\n",
      "Retrieving comments for 17ek5qx\n",
      "Retrieving comments for 17bue87\n",
      "Retrieving comments for 17b6h8r\n",
      "Retrieving comments for 17b0vxb\n",
      "Retrieving comments for 17apvhb\n",
      "Retrieving comments for 179ta5f\n",
      "Retrieving comments for 179ayz3\n",
      "Retrieving comments for 1792pi5\n",
      "Retrieving comments for 177cxlw\n",
      "Retrieving comments for 176xiau\n",
      "Retrieving comments for 175akwb\n",
      "Retrieving comments for 1738jly\n",
      "Retrieving comments for 1716odu\n",
      "Retrieving comments for 170w60r\n",
      "Retrieving comments for 1701u0z\n",
      "Retrieving comments for 16zsmqo\n",
      "Retrieving comments for 16zqjhy\n",
      "Retrieving comments for 16z8650\n",
      "Retrieving comments for 16yzqw7\n",
      "Retrieving comments for 16yyanh\n",
      "Retrieving comments for 16xp9v9\n",
      "Retrieving comments for 16vh29g\n",
      "Retrieving comments for 16ucfe1\n",
      "Retrieving comments for 16u9hh2\n",
      "Retrieving comments for 16to4en\n",
      "Retrieving comments for 16skguw\n",
      "Retrieving comments for 16rv229\n",
      "Retrieving comments for 16rsbua\n",
      "Retrieving comments for 16r8vdg\n",
      "Retrieving comments for 16q6sii\n",
      "Retrieving comments for 16pcucd\n",
      "Retrieving comments for 16oobi6\n",
      "Retrieving comments for 16omrza\n",
      "Retrieving comments for 16odppi\n",
      "Retrieving comments for 16m452i\n",
      "Retrieving comments for 16l6wg1\n",
      "Retrieving comments for 16jko5h\n",
      "Retrieving comments for 16jg5bu\n",
      "Retrieving comments for 16jcs12\n",
      "Retrieving comments for 16iqyit\n",
      "Retrieving comments for 16ilf1i\n",
      "Retrieving comments for 16idwz0\n",
      "Retrieving comments for 16ia857\n",
      "Retrieving comments for 16i0bop\n",
      "Retrieving comments for 16hzcjw\n",
      "Retrieving comments for 16hnqcc\n",
      "Retrieving comments for 16hk6lu\n",
      "Retrieving comments for 16hhw2c\n",
      "Retrieving comments for 16h15jw\n",
      "Retrieving comments for 16gzahv\n",
      "Retrieving comments for 16gwxc9\n",
      "Retrieving comments for 16gwibe\n",
      "Retrieving comments for 16gozwg\n",
      "Retrieving comments for 16gnvpz\n",
      "Retrieving comments for 16gck75\n",
      "Retrieving comments for 16gc93j\n",
      "Retrieving comments for 16g61b7\n",
      "Retrieving comments for 16g3wos\n",
      "Retrieving comments for 16g3hb9\n",
      "Retrieving comments for 16frubo\n",
      "Retrieving comments for 16fe47f\n",
      "Retrieving comments for 16f7rqt\n",
      "Retrieving comments for 16f5kg5\n",
      "Retrieving comments for 16f4jpz\n",
      "Retrieving comments for 16ewv5h\n",
      "Retrieving comments for 16ejf7s\n",
      "Retrieving comments for 16ehlvb\n",
      "Retrieving comments for 16dzawm\n",
      "Retrieving comments for 16damt2\n",
      "Retrieving comments for 16cubj5\n",
      "Retrieving comments for 16ctp69\n",
      "Retrieving comments for 16cl846\n",
      "Retrieving comments for 16cfm6g\n",
      "Retrieving comments for 16cfc58\n",
      "Retrieving comments for 16ccrsl\n",
      "Retrieving comments for 16bvtau\n",
      "Retrieving comments for 16buo3d\n",
      "Retrieving comments for 16bmo5k\n",
      "Retrieving comments for 16bipqi\n",
      "Retrieving comments for 16big02\n",
      "Retrieving comments for 16bgzv5\n",
      "Retrieving comments for 16bgy4y\n",
      "Retrieving comments for 16bfgr8\n",
      "Retrieving comments for 16b73jh\n",
      "Retrieving comments for 16b2a2z\n",
      "Retrieving comments for 16azrho\n",
      "Retrieving comments for 16az33m\n",
      "Retrieving comments for 16at7eu\n",
      "Retrieving comments for 16ar93z\n",
      "Retrieving comments for 16alsji\n",
      "Retrieving comments for 16a4atl\n",
      "Retrieving comments for 16a1tod\n",
      "Retrieving comments for 169v922\n",
      "Retrieving comments for 169ic78\n",
      "Retrieving comments for 1698ipu\n",
      "Retrieving comments for 1693gwh\n",
      "Retrieving comments for 167fx3q\n",
      "Retrieving comments for 167966q\n",
      "Retrieving comments for 166gtx8\n",
      "Retrieving comments for 165nvw6\n",
      "Retrieving comments for 165gul8\n",
      "Retrieving comments for 165fqh9\n",
      "Retrieving comments for 165fnsi\n",
      "Retrieving comments for 165e2in\n",
      "Retrieving comments for 165bqnb\n",
      "Retrieving comments for 162jale\n",
      "Retrieving comments for 1619kk8\n",
      "Retrieving comments for 1618xlw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving comments for 1615gm5\n",
      "Retrieving comments for 16074g2\n",
      "Retrieving comments for 15veb3t\n",
      "Retrieving comments for 15uvzrm\n",
      "Retrieving comments for 15uadbv\n",
      "Retrieving comments for 15rrbw9\n",
      "Retrieving comments for 15osom0\n",
      "Retrieving comments for 15npna5\n",
      "Retrieving comments for 15j0dw7\n",
      "Retrieving comments for 15j05yi\n",
      "Retrieving comments for 15h77r8\n",
      "Retrieving comments for 15gas3f\n",
      "Retrieving comments for 15fkp81\n",
      "Retrieving comments for 15ecyz2\n",
      "Retrieving comments for 15dv54t\n",
      "Retrieving comments for 15a497y\n",
      "Retrieving comments for 15a31rp\n",
      "Retrieving comments for 158lgp4\n",
      "Retrieving comments for 1540jsr\n",
      "Retrieving comments for 153414c\n",
      "Retrieving comments for 1532uh2\n",
      "Retrieving comments for 152wq7x\n",
      "Retrieving comments for 14ykvrx\n",
      "Retrieving comments for 14xlbng\n",
      "Retrieving comments for 14x218w\n",
      "Retrieving comments for 14uw7i2\n",
      "Retrieving comments for 14s26on\n",
      "Retrieving comments for 14qgcpe\n",
      "Retrieving comments for 14p5dql\n",
      "Retrieving comments for 14o3vum\n",
      "Retrieving comments for 14my41r\n",
      "Retrieving comments for 14m4d4v\n",
      "Retrieving comments for 14k8ywh\n",
      "Retrieving comments for 14htij1\n",
      "Retrieving comments for 14hh920\n",
      "Retrieving comments for 14gvbp0\n",
      "Retrieving comments for 14gsqpl\n",
      "Retrieving comments for 14fy6w4\n",
      "Retrieving comments for 14fl8ez\n",
      "Retrieving comments for 14ffpo7\n",
      "Retrieving comments for 14fcxvx\n",
      "Retrieving comments for 14cfoav\n",
      "Retrieving comments for 14a1bg1\n",
      "Retrieving comments for 1496l9t\n",
      "Retrieving comments for 1476jre\n",
      "Retrieving comments for 1455j4m\n",
      "Retrieving comments for 143l1mf\n",
      "Retrieving comments for 143cfef\n",
      "Retrieving comments for 142nyjo\n",
      "Retrieving comments for 142ewp8\n",
      "Retrieving comments for 141z97e\n",
      "Retrieving comments for 14125cl\n",
      "Retrieving comments for 13zjdof\n",
      "Retrieving comments for 13z9eft\n",
      "Retrieving comments for 13wuza4\n",
      "Retrieving comments for 13wsltd\n",
      "Retrieving comments for 13uukf7\n",
      "Retrieving comments for 13ullzv\n",
      "Retrieving comments for 13ue2tq\n",
      "Retrieving comments for 13sy5xr\n",
      "Retrieving comments for 13s4g9l\n",
      "Retrieving comments for 13rq7hk\n",
      "Retrieving comments for 13rat36\n",
      "Retrieving comments for 13qh0r1\n",
      "Retrieving comments for 13qawd2\n",
      "Retrieving comments for 13pfsbl\n",
      "Retrieving comments for 13ml2hs\n",
      "Retrieving comments for 13kabbj\n",
      "Retrieving comments for 13k2ycp\n",
      "Retrieving comments for 13j6mkb\n",
      "Retrieving comments for 13ig6sy\n",
      "Retrieving comments for 13dwx43\n",
      "Retrieving comments for 13dw2mo\n",
      "Retrieving comments for 13dlro9\n",
      "Retrieving comments for 13d45f8\n",
      "Retrieving comments for 13b7vje\n",
      "Retrieving comments for 138ei33\n",
      "Retrieving comments for 138dxqp\n",
      "Retrieving comments for 137y1aw\n",
      "Retrieving comments for 137dgwp\n",
      "Retrieving comments for 135in3f\n",
      "Retrieving comments for 130fi8w\n",
      "Retrieving comments for 12zqcd1\n",
      "Retrieving comments for 12yxidn\n",
      "Retrieving comments for 12yvsds\n",
      "Retrieving comments for 12womkl\n",
      "Retrieving comments for 12w2f3r\n",
      "Retrieving comments for 12rntzf\n",
      "Retrieving comments for 12jqnzf\n",
      "Retrieving comments for 12c9ged\n",
      "Retrieving comments for 12bt6fo\n",
      "Retrieving comments for 12bk5vl\n",
      "Retrieving comments for 12b9gu0\n",
      "Retrieving comments for 125f9xk\n",
      "Retrieving comments for 11yck0r\n",
      "Retrieving comments for 11x7b19\n",
      "Retrieving comments for 11rschm\n",
      "Retrieving comments for 11n2uhc\n",
      "Retrieving comments for 11ekrxo\n",
      "Retrieving comments for 11dlbhx\n",
      "Retrieving comments for 11c1ju9\n",
      "Retrieving comments for 11bz2tp\n",
      "Retrieving comments for 11a5453\n",
      "Retrieving comments for 116opii\n",
      "Retrieving comments for 115g6ar\n",
      "Retrieving comments for 10y51vb\n",
      "Retrieving comments for 10xs4iu\n",
      "Retrieving comments for 10xdc3d\n",
      "Retrieving comments for 10piywu\n",
      "Retrieving comments for 10pfje7\n",
      "Retrieving comments for 10p8tf9\n",
      "Retrieving comments for 10h3kiz\n",
      "Retrieving comments for 10h3j7z\n",
      "Retrieving comments for 10fvfo4\n",
      "Retrieving comments for 10f47wx\n",
      "Retrieving comments for 10ermcc\n",
      "Retrieving comments for 10eko79\n",
      "Retrieving comments for 10eem7i\n",
      "Retrieving comments for 10eb6gj\n",
      "Retrieving comments for 106sfs6\n",
      "Retrieving comments for 106hzo8\n",
      "Retrieving comments for 1025dql\n",
      "Retrieving comments for 101ngd8\n",
      "Retrieving comments for zydzkn\n",
      "Retrieving comments for ztstry\n",
      "Retrieving comments for zp86a8\n",
      "Retrieving comments for znnfuj\n",
      "Retrieving comments for zly190\n",
      "Retrieving comments for zkyypg\n",
      "Retrieving comments for zk30cw\n",
      "Retrieving comments for z8riya\n",
      "Retrieving comments for z1evur\n",
      "Retrieving comments for ylupqz\n",
      "Retrieving comments for 17gjp3d\n",
      "Retrieving comments for 17e6ilr\n",
      "Retrieving comments for 17bvhkt\n",
      "Retrieving comments for 179wpki\n",
      "Retrieving comments for 173yn7e\n",
      "Retrieving comments for 16xpfu6\n",
      "Retrieving comments for 16v1w9c\n",
      "Retrieving comments for 16rvacs\n",
      "Retrieving comments for 16q6jm2\n",
      "Retrieving comments for 16oq56r\n",
      "Retrieving comments for 16je8eg\n",
      "Retrieving comments for 16iqa3w\n",
      "Retrieving comments for 16hkc5o\n",
      "Retrieving comments for 16bmhw9\n",
      "Retrieving comments for 1659nea\n",
      "Retrieving comments for 1614ncj\n",
      "Retrieving comments for 14vplsc\n",
      "Retrieving comments for 14mxhgq\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./comments.csv'):\n",
    "    with open('./comments.csv', 'w') as f:\n",
    "        out = csv.writer(f)\n",
    "        out.writerow(['id',\n",
    "                      'body',\n",
    "                      'author', \n",
    "                      'created_utc', \n",
    "                      'parent_id', \n",
    "                      'submission_id', \n",
    "                      'tot_awards_received', \n",
    "                      'ups', \n",
    "                      'downs', \n",
    "                      'score'])\n",
    "# again, we set in the submission data for the \"comments retrieved\" to initially be false so we can locate the comments that haven't been retrieved.\n",
    "for submission_id in df.loc[df.comments_retrieved == False, 'id']:\n",
    "    # Creating this print command can allow us to track how many comments are being retrieved, as a progress check while the code is running\n",
    "    print(f'Retrieving comments for {submission_id}')\n",
    "    submission = reddit.submission(id=submission_id)\n",
    "    # This sets the limit to None, which means that it will retrieve all comments, instead .\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    # Because we're only storing whether a submission was retrieved, we save all the comments and write them at the same time in the curr comments.\n",
    "    all_comments = []\n",
    "    # We again need to add this in in case an \"author's name is None\" because of the error that can happen if someone no longer has a reddit accound, but the post is still online\n",
    "    for comment in submission.comments.list():\n",
    "        try:\n",
    "            name = comment.author.name\n",
    "        except AttributeError:\n",
    "            name = None\n",
    "        all_comments.append([comment.id, \n",
    "                        comment.body, \n",
    "                        name, \n",
    "                        comment.created_utc, \n",
    "                        comment.parent_id,\n",
    "                        submission.id,\n",
    "                        comment.total_awards_received,\n",
    "                        comment.ups,\n",
    "                        comment.downs,\n",
    "                        comment.score\n",
    "                        ])\n",
    "    with open('./comments.csv', 'a') as f:\n",
    "        out = csv.writer(f)\n",
    "        out.writerows(curr_comments)\n",
    "    # This allows us to change/update the paramater and create the \"save game\" situation in case the error message occurs and change the False to True\n",
    "    df.loc[df.id == submission_id, 'comments_retrieved'] = True\n",
    "    df.to_csv('./submissions.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af1dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4f1579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>tot_awards_received</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k4p2aih</td>\n",
       "      <td>Love how there's actual therapy going on in th...</td>\n",
       "      <td>seafoamteal</td>\n",
       "      <td>1.697199e+09</td>\n",
       "      <td>t3_176x1xq</td>\n",
       "      <td>176x1xq</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k4pp7y3</td>\n",
       "      <td>I can’t see the mandatory; “All turds of mass ...</td>\n",
       "      <td>First-Can3099</td>\n",
       "      <td>1.697209e+09</td>\n",
       "      <td>t3_176x1xq</td>\n",
       "      <td>176x1xq</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k4pjse8</td>\n",
       "      <td>Big difference to what was inscribed on the ba...</td>\n",
       "      <td>Michling99</td>\n",
       "      <td>1.697207e+09</td>\n",
       "      <td>t3_176x1xq</td>\n",
       "      <td>176x1xq</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k4qbfye</td>\n",
       "      <td>Wow girls get words on the wall we get shit sm...</td>\n",
       "      <td>Verlop451</td>\n",
       "      <td>1.697217e+09</td>\n",
       "      <td>t3_176x1xq</td>\n",
       "      <td>176x1xq</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k4qligd</td>\n",
       "      <td>The Newman toilets are next level. You always ...</td>\n",
       "      <td>LadyShadington</td>\n",
       "      <td>1.697221e+09</td>\n",
       "      <td>t3_176x1xq</td>\n",
       "      <td>176x1xq</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               body          author  \\\n",
       "0  k4p2aih  Love how there's actual therapy going on in th...     seafoamteal   \n",
       "1  k4pp7y3  I can’t see the mandatory; “All turds of mass ...   First-Can3099   \n",
       "2  k4pjse8  Big difference to what was inscribed on the ba...      Michling99   \n",
       "3  k4qbfye  Wow girls get words on the wall we get shit sm...       Verlop451   \n",
       "4  k4qligd  The Newman toilets are next level. You always ...  LadyShadington   \n",
       "\n",
       "    created_utc   parent_id submission_id  tot_awards_received  ups  downs  \\\n",
       "0  1.697199e+09  t3_176x1xq       176x1xq                    0   48      0   \n",
       "1  1.697209e+09  t3_176x1xq       176x1xq                    0   13      0   \n",
       "2  1.697207e+09  t3_176x1xq       176x1xq                    0   10      0   \n",
       "3  1.697217e+09  t3_176x1xq       176x1xq                    0    8      0   \n",
       "4  1.697221e+09  t3_176x1xq       176x1xq                    0    9      0   \n",
       "\n",
       "   score  \n",
       "0     48  \n",
       "1     13  \n",
       "2     10  \n",
       "3      8  \n",
       "4      9  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
